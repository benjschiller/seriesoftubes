import merge
from numpy.core.fromnumeric import std 
import collections

def count_seqs(iterable, rc=True):
	'''count_seqs takes as input an iterable that yields sequences, and then returns the counts of each sequence as a defaultdict (similar to dict, can be recast as dict type).

Sorting: Use dictSort to sort, if needed.

Reverse complements: if rc=True, count_seqs will count reverse complements as the same sequence and use the alphabetically prior sequence as the key. if rc=False, reverse complements will be treated as different sequences.

Case: Please note, if sequences contain mixed upper/lower case, you should change case before using count_seqs (if you want them to be counted the same).'''
	seqCounts = collections.defaultdict(lambda: 0)
	if rc:
		iterableABC = ( merge.mergesort(seq,rc(seq),order='ascending')[0] for seq in iterable )
		for seqABC in iterableABC: seqCounts[seqABC]+=1
	else: # if not rc
		for seq in iterable: seqCounts[seq]+=1
	return seqCounts

def count_compare(a,b,rc=False):
	'''mergecompare takes two default dictionaries (defaultdict objects), a and b, each with default factory "lambda: 0" and key-value pairs that specify the counts (value) of each sequence (key), and returns a new dictionary whose values are tuples (value_a,value_b), the values from a and b.

Reverse complements: if rc=True, count_seqs will count reverse complements as the same sequence and use the alphabetically prior sequence as the key. if rc=False, reverse complements will be treated as different sequences. If you have already ensured that the keys meet this condition, you should use rc=False, but rc=True is also safe.

note: defaultdict is in the collections module of the standard library
	'''
	if not type(a)==collections.defaultdict or not type(b)==collections.defaultdict: raise ValueError('a and b must be default dictionaries (collections.defaultdict)')
	# proceed
	comparedCounts = {}
	for k in set( a.keys(), b.keys() ): comparedCounts[k] = (a[k],b[k])
	return comparedCounts

def analyze_sites(L):
	'''
analyze_sites with optimizations. requires the following input format:
seq score cdist cons
'''
	# column definitions for reference / calling
	x0 = 0 # x0 is sequence
	x1 = 1 # x1 is score (Ri)
	x2 = 2 # x2 is peaklength
	x3 = 3 # x3 is cdist
	x4 = 4 # x4 is conservation score

	# columns are seq, score, peaklength, cdist, cons
	# build an array scalar with the correct column types
	for x in L:
		# forces sequences to uppercase
		x[x0] = x[x0].upper()
		# forces length to int
		x[x2] = int(x[x2])
		# forces cdist to int
		x[x3] = int(x[x3])
		# forces cons score to floating point
		# and correct nan
		if x[x4]=='nan': x[x4] = 0.0
		else: x[x4] = float(x[x4])
	# sort the list by sequence (arbitrarily)
	L = merge.mergesort(L, x0)
	# Part 3: continue with analysis
	analyzedSeqs = []
	counter = len(L)
	while counter > 0:
		site = L.pop()
		counter -= 1
		seq = site[x0]
		score = site[x1]
		# start a list of dists, absdists, cscores, we'll sum later
		i = 1
		plengths = [ site[x2] ]
		dists = [ site[x3] ]
		absdists = [ abs(site[x3]) ]
		cscores = [ site[x4] ]
		while True: # grab sequences that match
			try: y = L.pop()
			except IndexError: break
			counter -= 1
			# look if we match the last entry
			if y[x0] == seq:
				i += 1
				plengths.append(y[x2])
				dists.append(y[x3])
				absdists.append( abs( y[x3] ) )
				cscores.append(y[x4])
			# if we don't, escape to previous loop
			else:
				# append back
				L.append(y)
				break
		# append seq, sum of scores, # of instances
		avgPlength = float(sum(plengths))/i
		avgDist = float(sum(dists))/i
		avgAbsdist = float(sum(absdists))/i
		distErr = std(absdists)
		analyzedSeqs.append([seq, score, i, sum(cscores), avgPlength, avgDist, avgAbsdist,distErr])
	analyzedSeqs.reverse()
	return merge.mergesort(analyzedSeqs,x2)

def complement(nucleotide):
	'''returns the complement of a single nucleotide'''
	complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A', 'a': 't', 'c': 'g', 'g': 'c', 't': 'a'}
	return complement.setdefault(nucleotide,'N')

def rc(seq):
	'''returns the reverse complement of a sequence'''
	L = [complement(s) for s in seq]
	L.reverse()
	return ''.join(L)

def calculate_mean(motifInfo,option=0):
	'''calculates a mean about the peak center using motifInfo internally generated by averageSites()'''
	# motifInfo is formatted as [motif,score,cdist]
#	motifs = motifInfo[0]
	scores = motifInfo[1]
	cdists = motifInfo[2]
	numMotifs = len(motifInfo[2])
	if option==0:
		return sum( cdists ) / numMotifs
	if option==1:
		RMS = ( sum([x**2 for x in cdists]) / numMotifs)**0.5
		return RMS 
	if option==2:
		weightedMean = 0
		for i in range(numMotifs):
			scores[i] = 30-scores[i]
			weightedMean = weightedMean + cdists[i] * (scores[i])
		weightedMean = weightedMean / numMotifs / sum( scores )
		return weightedMean
	if option==3:
		if numMotifs==1: return cdists[0]
		weightedMean = 0
		dBsum = 0
		minScore = min(scores)
		for i in range(numMotifs):
			dBdiff = scores[i] - minScore
			dBsum = dBsum + dBdiff
			weightedMean = weightedMean + cdists[i] / dBdiff
		if dBsum == 0: return sum(cdists) / numMotifs
		weightedMean = weightedMean / numMotifs * dBsum
		return weightedMean

def delete_even_lines(f):
	fpointer = open(f, 'r')
	x = fpointer.readlines()
	fpointer = open(f, 'w')
	i = 0
	for line in x:
		i += 1
		i %= 2
		if i==1: fpointer.write(line)
	return True
